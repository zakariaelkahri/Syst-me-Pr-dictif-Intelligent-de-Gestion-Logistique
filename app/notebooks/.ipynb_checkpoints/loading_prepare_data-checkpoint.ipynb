{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69411ae3",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d565208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Days for shipping (real): integer (nullable = true)\n",
      " |-- Days for shipment (scheduled): integer (nullable = true)\n",
      " |-- Benefit per order: double (nullable = true)\n",
      " |-- Sales per customer: double (nullable = true)\n",
      " |-- Delivery Status: string (nullable = true)\n",
      " |-- Late_delivery_risk: integer (nullable = true)\n",
      " |-- Category Id: integer (nullable = true)\n",
      " |-- Category Name: string (nullable = true)\n",
      " |-- Customer City: string (nullable = true)\n",
      " |-- Customer Country: string (nullable = true)\n",
      " |-- Customer Email: string (nullable = true)\n",
      " |-- Customer Fname: string (nullable = true)\n",
      " |-- Customer Id: integer (nullable = true)\n",
      " |-- Customer Lname: string (nullable = true)\n",
      " |-- Customer Password: string (nullable = true)\n",
      " |-- Customer Segment: string (nullable = true)\n",
      " |-- Customer State: string (nullable = true)\n",
      " |-- Customer Street: string (nullable = true)\n",
      " |-- Customer Zipcode: integer (nullable = true)\n",
      " |-- Department Id: integer (nullable = true)\n",
      " |-- Department Name: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Market: string (nullable = true)\n",
      " |-- Order City: string (nullable = true)\n",
      " |-- Order Country: string (nullable = true)\n",
      " |-- Order Customer Id: integer (nullable = true)\n",
      " |-- order date (DateOrders): string (nullable = true)\n",
      " |-- Order Id: integer (nullable = true)\n",
      " |-- Order Item Cardprod Id: integer (nullable = true)\n",
      " |-- Order Item Discount: double (nullable = true)\n",
      " |-- Order Item Discount Rate: double (nullable = true)\n",
      " |-- Order Item Id: integer (nullable = true)\n",
      " |-- Order Item Product Price: double (nullable = true)\n",
      " |-- Order Item Profit Ratio: double (nullable = true)\n",
      " |-- Order Item Quantity: integer (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      " |-- Order Item Total: double (nullable = true)\n",
      " |-- Order Profit Per Order: double (nullable = true)\n",
      " |-- Order Region: string (nullable = true)\n",
      " |-- Order State: string (nullable = true)\n",
      " |-- Order Status: string (nullable = true)\n",
      " |-- Order Zipcode: integer (nullable = true)\n",
      " |-- Product Card Id: integer (nullable = true)\n",
      " |-- Product Category Id: integer (nullable = true)\n",
      " |-- Product Description: string (nullable = true)\n",
      " |-- Product Image: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Product Price: double (nullable = true)\n",
      " |-- Product Status: integer (nullable = true)\n",
      " |-- shipping date (DateOrders): string (nullable = true)\n",
      " |-- Shipping Mode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparksession import spark\n",
    "\n",
    "df = spark.read.csv('../data/dataset/DataCoSupplyChainDataset.csv',header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ba4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e684653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import functions as f\n",
    "df_cleaned = df.filter(f.col('Order Status') != 'CANCELED')\n",
    "df_cleaned.filter(f.col('Order Status') =='CANCELED' ).count()\n",
    "\n",
    "df_cleaned.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "# Product Description,Order Zipcode have null values\n",
    "# df_cleaned = df.drop('Order Zipcode', 'Product Description', 'Customer Email', 'Customer Password' )\n",
    "\n",
    "df_cleaned = df_cleaned.withColumn(\n",
    "    'Shipping Mode',\n",
    "    f.when(f.col('Shipping Mode') == 'Same Day', 'First Class')\n",
    "    .otherwise(f.col('Shipping Mode'))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3735a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5809ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_redondantes  = [\n",
    "    # 'Type',\n",
    "    'Days for shipping (real)',\n",
    "    'Delivery Status',\n",
    "    'Customer Fname',\n",
    "    'Customer Lname',\n",
    "    'Customer Email',\n",
    "    'Customer Password',\n",
    "    'Order Id',\n",
    "    'Customer Id',\n",
    "    'Order Item Id',\n",
    "    'Order Customer Id',\n",
    "    'Order Item Cardprod Id',\n",
    "    'Product Card Id',\n",
    "    'Product Category Id',\n",
    "    'Department Id',\n",
    "    'Product Description',\n",
    "    'Product Image',\n",
    "    'Product Name'  ,\n",
    "    'Order Item Total',\n",
    "    'Order Profit Per Order',\n",
    "    'Benefit per order',\n",
    "    'Sales per customer',\n",
    "    'Order Item Profit Ratio',\n",
    "    'Customer Country',\n",
    "    'rder Zipcode',\n",
    "    'Product Status',\n",
    "    'Customer State',\n",
    "    'Customer Street',\n",
    "    'Customer Zipcode',\n",
    "    'Department Name',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'Market',\n",
    "    'Order City',\n",
    "    'Order Country',\n",
    "    'Order Item Discount',\n",
    "    'Order Item Discount Rate',\n",
    "    'Order Item Product Price',\n",
    "    # 'Order Item Quantity',\n",
    "    'Sales',\n",
    "    'Order Status',\n",
    "    'Product Card Id',\n",
    "    'Product Price'\n",
    "    'Product Status',\n",
    "    'Shipping date (DateOrders)',\n",
    "    'Shipping Mode',\n",
    "    'Category Name',\n",
    "    'Customer City',\n",
    "    'Order Zipcode',\n",
    "    'Order State',\n",
    "    'Product Price',\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df_columns_cleaned =  df_cleaned.drop(*columns_redondantes)\n",
    "\n",
    "df_columns_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf7ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_cleaned = df_columns_cleaned.withColumn(\n",
    "    'order_date',\n",
    "    f.to_timestamp('order date (DateOrders)', \"M/d/yyyy H:mm\")\n",
    ")\n",
    "\n",
    "df_columns_cleaned = df_columns_cleaned.withColumn('order_month', f.month('order_date'))\n",
    "\n",
    "df_columns_cleaned = df_columns_cleaned.drop('order date (DateOrders)', 'order_date')\n",
    "\n",
    "df_columns_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eeaf8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_minor = df_columns_cleaned.filter(f.col('Late_delivery_risk') == 0)\n",
    "rslt_major = df_columns_cleaned.filter(f.col('Late_delivery_risk') == 1)\n",
    "\n",
    "print(rslt_minor.count(), '>==<', rslt_major.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_count = rslt_major.count()\n",
    "minor_count = rslt_minor.count()\n",
    "\n",
    "n_repeats = int(major_count / minor_count)\n",
    "\n",
    "n_remainder = major_count % minor_count\n",
    "\n",
    "replicated_df = rslt_minor.withColumn(\n",
    "    \"replicator\",\n",
    "    f.explode(f.array([f.lit(i) for i in range(n_repeats)]))\n",
    ").drop(\"replicator\")\n",
    "\n",
    "replicated_df.count()\n",
    "\n",
    "remainder_df = rslt_minor.orderBy(f.rand(seed=42)).limit(n_remainder)\n",
    "\n",
    "balanced_df = rslt_major.unionAll(replicated_df).unionAll(remainder_df)\n",
    "\n",
    "balanced_df.groupBy(\"Late_delivery_risk\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c760841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "927bc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a53780",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "cat_cols = []\n",
    "\n",
    "for col, type in balanced_df.dtypes:\n",
    "    if type in ['int', 'double'] :\n",
    "        num_cols.append(col)\n",
    "    else: \n",
    "        cat_cols.append(col)\n",
    "        \n",
    "        \n",
    "cat_indexed = [\n",
    "    'Customer Segment(indexed)',\n",
    "    'Order Region(indexed)',\n",
    "    'Type(indexed)'\n",
    "    ]\n",
    "\n",
    "\n",
    "cat_encoded = [    \n",
    "    'Customer Segment(encoded)',\n",
    "    'Order Region(encoded)',\n",
    "    'Type(encoded)']\n",
    "\n",
    "print(num_cols,cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "757a0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "train_df, test_df = balanced_df.randomSplit([0.8, 0.2], seed=42)\n",
    "num_cols.remove('Late_delivery_risk')\n",
    "print(num_cols)\n",
    "indexer = StringIndexer(inputCols=cat_cols, outputCols=cat_indexed)\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=cat_indexed, outputCols=cat_encoded)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=num_cols + cat_encoded, outputCol='features')\n",
    "\n",
    "random_forest = RandomForestClassifier(labelCol='Late_delivery_risk', featuresCol='features')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94cd7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_index = balanced_df.rdd.zipWithIndex().toDF([\"row\", \"index\"])\n",
    "df_test_selected = df_with_index.filter(\"index <= 3\").select(\"row.*\")\n",
    "balanced_df = df_with_index.filter(\"index >= 3\").select(\"row.*\")\n",
    "\n",
    "df_test_selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73f3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipline1 = Pipeline(stages=[indexer, encoder, assembler, random_forest])\n",
    "\n",
    "\n",
    "model_rf = pipline1.fit(train_df)\n",
    "preds_rf = model_rf.transform(test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf710e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f51c6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    labelCol=\"Late_delivery_risk\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcf63652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipline2 = Pipeline(stages=[indexer, encoder, assembler, log_reg])\n",
    "\n",
    "\n",
    "model_lr = pipline2.fit(train_df)\n",
    "preds_lr= model_lr.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6730da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ccba17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59c2e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=\"Late_delivery_risk\", featuresCol=\"features\", maxIter=50)\n",
    "\n",
    "pipline3 = Pipeline(stages=[indexer, encoder, assembler, gbt])\n",
    "\n",
    "model_gbt = pipline3.fit(train_df)\n",
    "preds_gbt = model_gbt.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143c389",
   "metadata": {},
   "source": [
    "# Évaluation et Comparaison des Modèles\n",
    "\n",
    "Nous allons maintenant évaluer les performances des trois modèles (Random Forest, Logistic Regression, Gradient Boosting Tree) en utilisant diverses métriques de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5482e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "auc_eval = BinaryClassificationEvaluator(\n",
    "    labelCol='Late_delivery_risk', rawPredictionCol= 'rawPrediction', metricName='areaUnderROC'\n",
    ")\n",
    "\n",
    "#auc eval\n",
    "\n",
    "rf_auc = auc_eval.evaluate(preds_rf)\n",
    "lr_auc = auc_eval.evaluate(preds_lr)\n",
    "gbt_auc = auc_eval.evaluate(preds_gbt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b09f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol='Late_delivery_risk', predictionCol='prediction', metricName='accuracy'\n",
    ")\n",
    "\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol='Late_delivery_risk', predictionCol='prediction', metricName='f1'\n",
    ")\n",
    "\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol='Late_delivery_risk', predictionCol='prediction', metricName='weightedPrecision'\n",
    "    \n",
    ")\n",
    "\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol='Late_delivery_risk', predictionCol='prediction', metricName='weightedRecall'\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# eval with accuracy\n",
    "rf_acc = acc_eval.evaluate(preds_rf)\n",
    "lr_acc = acc_eval.evaluate(preds_lr)\n",
    "gbt_acc = acc_eval.evaluate(preds_gbt)\n",
    "\n",
    "# eval with f1\n",
    "rf_f1 = f1_eval.evaluate(preds_rf)\n",
    "lr_f1 = f1_eval.evaluate(preds_lr)\n",
    "gbt_f1 = f1_eval.evaluate(preds_gbt)\n",
    "\n",
    "# precision eval: \n",
    "rf_precision = precision_eval.evaluate(preds_rf)\n",
    "lr_precision = precision_eval.evaluate(preds_lr)\n",
    "gbt_precision = precision_eval.evaluate(preds_gbt)\n",
    "\n",
    "# recall eval: \n",
    "rf_recall = recall_eval.evaluate(preds_rf)\n",
    "lr_recall = recall_eval.evaluate(preds_lr)\n",
    "gbt_recall = recall_eval.evaluate(preds_gbt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a92c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------- LR\")\n",
    "print(f\"AUC = {lr_auc:.3f}\")\n",
    "print(f\"Accuracy = {lr_acc:.3f}\")\n",
    "print(f\"F1-score = {lr_f1:.3f}\")\n",
    "print(f\"Precision = {lr_precision:.3f}\")\n",
    "print(f\"Recall = {lr_recall:.3f}\")\n",
    "\n",
    "print(\"\\n------------- RF\")\n",
    "print(f\"AUC = {rf_auc:.3f}\")\n",
    "print(f\"Accuracy = {rf_acc:.3f}\")\n",
    "print(f\"F1-score = {rf_f1:.3f}\")\n",
    "print(f\"Precision = {rf_precision:.3f}\")\n",
    "print(f\"Recall = {rf_recall:.3f}\")\n",
    "\n",
    "print(\"\\n------------- GBT\")\n",
    "print(f\"AUC = {gbt_auc:.3f}\")\n",
    "print(f\"Accuracy = {gbt_acc:.3f}\")\n",
    "print(f\"F1-score = {gbt_f1:.3f}\")\n",
    "print(f\"Precision = {gbt_precision:.3f}\")\n",
    "print(f\"Recall = {gbt_recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa084629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Random forest girdsearch :\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(random_forest.numTrees, [50,100,200])\n",
    "            .addGrid(random_forest.maxDepth, [5, 20])\n",
    "            .addGrid(random_forest.maxBins, [16, 64])\n",
    "            .build()\n",
    "            )\n",
    "\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipline1,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=auc_eval,\n",
    "    numFolds=5,\n",
    "    seed=42,\n",
    "    # parallelism=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b529c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rf_model = cv.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31ca3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = cv_rf_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af4bd3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_param = best_rf_model.stages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0796833",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best numTrees:\", best_model_param.getNumTrees)\n",
    "print(\"Best maxDepth:\", best_model_param.getMaxDepth())\n",
    "print(\"Best maxBins:\", best_model_param.getMaxBins())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f557ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rf_preds = best_rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f20c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_auc = auc_eval.evaluate(cv_rf_preds)\n",
    "# lr_auc = auc_eval.evaluate(preds_lr)\n",
    "# gbt_auc = auc_eval.evaluate(preds_gbt)\n",
    "\n",
    "# eval with accuracy\n",
    "rf_cv_acc = acc_eval.evaluate(cv_rf_preds)\n",
    "# lr_acc = acc_eval.evaluate(preds_lr)\n",
    "# gbt_acc = acc_eval.evaluate(preds_gbt)\n",
    "\n",
    "# eval with f1\n",
    "rf_cv_f1 = f1_eval.evaluate(cv_rf_preds)\n",
    "# lr_f1 = f1_eval.evaluate(preds_lr)\n",
    "# gbt_f1 = f1_eval.evaluate(preds_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c8d7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------- rf\")\n",
    "print(f\"AUC = {rf_cv_auc:.3f}\")\n",
    "print(f\"Accuracy = {rf_cv_acc:.3f}\")\n",
    "print(f\"F1-score = {rf_cv_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38507675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "868e18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# gbt girdsearch :\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(gbt.maxDepth, [3, 5,10])\n",
    "            .addGrid(gbt.maxBins, [32, 64])\n",
    "            .addGrid(gbt.maxIter, [10, 30, 40])\n",
    "            .addGrid(gbt.stepSize, [0.05, 0.1, 0.2])  \n",
    "            .build()\n",
    "            )\n",
    "\n",
    "\n",
    "cv_gbt = CrossValidator(\n",
    "    estimator=pipline3,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=auc_eval,\n",
    "    numFolds=5,\n",
    "    seed=42,\n",
    "    parallelism=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6289229",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gbt_model = cv_gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f895ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbt_model = cv_gbt_model.bestModel\n",
    "\n",
    "best_gbt_params = best_gbt_model.stages[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d57429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best maxDepth:\", best_gbt_params.getMaxDepth())\n",
    "print(\"Best maxBins:\", best_gbt_params.getMaxBins())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "142f97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gbt_preds = best_gbt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a20de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_auc = auc_eval.evaluate(cv_rf_preds)\n",
    "# lr_auc = auc_eval.evaluate(preds_lr)\n",
    "gbt_cv_auc = auc_eval.evaluate(cv_gbt_preds)\n",
    "\n",
    "# eval with accuracy\n",
    "rf_cv_acc = acc_eval.evaluate(cv_rf_preds)\n",
    "# lr_acc = acc_eval.evaluate(preds_lr)\n",
    "gbt_cv_acc = acc_eval.evaluate(cv_gbt_preds)\n",
    "\n",
    "# eval with f1\n",
    "rf_cv_f1 = f1_eval.evaluate(cv_rf_preds)\n",
    "# lr_f1 = f1_eval.evaluate(preds_lr)\n",
    "gbt_cv_f1 = f1_eval.evaluate(cv_gbt_preds)\n",
    "\n",
    "# precision eval: \n",
    "rf_cv_precision = precision_eval.evaluate(cv_rf_preds)\n",
    "# lr_precision = precision_eval.evaluate(preds_lr)\n",
    "gbt_cv_precision = precision_eval.evaluate(cv_gbt_preds)\n",
    "\n",
    "# recall eval: \n",
    "rf_cv_recall = recall_eval.evaluate(cv_rf_preds)\n",
    "# lr_recall = recall_eval.evaluate(preds_lr)\n",
    "gbt_cv_recall = recall_eval.evaluate(cv_gbt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47939ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------- RF\")\n",
    "print(f\"AUC = {rf_cv_auc:.3f}\")\n",
    "print(f\"Accuracy = {rf_cv_acc:.3f}\")\n",
    "print(f\"F1-score = {rf_cv_f1:.3f}\")\n",
    "print(f\"Precision = {rf_cv_precision:.3f}\")\n",
    "print(f\"Recall = {rf_cv_recall:.3f}\")\n",
    "\n",
    "print(\"\\n------------- GBT\")\n",
    "print(f\"AUC = {gbt_cv_auc:.3f}\")\n",
    "print(f\"Accuracy = {gbt_cv_acc:.3f}\")\n",
    "print(f\"F1-score = {gbt_cv_f1:.3f}\")\n",
    "print(f\"Precision = {gbt_cv_precision:.3f}\")\n",
    "print(f\"Recall = {gbt_cv_recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb3657f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path = './models/rf_best_model'\n",
    "\n",
    "try:\n",
    "    best_rf_model.write().overwrite().save(best_path)\n",
    "    print(f\"\\n✅ Best PipelineModel saved successfully at : {best_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error while saving the best PipelineModel: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6952baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_path = './models/gbt_model'\n",
    "\n",
    "try:\n",
    "    cv_gbt_model.write().overwrite().save(gbt_path)\n",
    "    print(f\"\\n✅ Modèle gbt sauvegardé avec succès à : {gbt_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Erreur lors de la sauvegarde du modèle GBT : {e}\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
